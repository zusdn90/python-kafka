# python-kafka

### Producer 주요 옵션
- bootstrap.servers
  - 카프카 클러스터는 클러스터 마스터라는 개념이 없기 때문에 클러스터 내 모든 서버가 클라이언의 요청을 받을 수 있습니다. 
    해당 옵션은 카프카 클러스터에 처음 연결을 하기 위한 호스트와 포트 정보로 구성된 리스트 정보를 나타냅니다.

- acks: 프로듀서가 카프카 토픽의 리더에게 메시지를 보낸 후 요청을 완료하기 전 ack의 수입니다.
  - acks=0: 프로듀서는 서버로부터 어떠한 ack도 기다리지 않습니다. 이 경우 서버가 데이터를 받았는지 보장하지 않고, 클라이언트는 전송 실패에 대한 결과를 알지 못하기 때문에 재요청 설정도 적용되지 않습니다. 메시지가 손실될 수 있지만, 서버로부터 ack에 대한 응답을 기다리지 않기 때문에 매우 빠르게 메시지를 보낼 수 있어 높은 처리량을 얻을 수 있습니다.
  - acks=1: 리더는 데이터를 기록하지만, 모든 팔로워는 확인하지 않습니다. 이 경우 일부 데이터의 손실이 발생할 수 있습니다.
  - acks=all or -1: 리더는 ISR의 팔로워로부터 데이터에 대한 ack를 기다립니다. 하나의 팔로워가 있는 한 데이터는 손실되지 않으며, 데이터 무손실에 대해 가장 강력하게 보장합니다.

- buffer.memory
  - 프로듀서가 카프카 서버로 데이터를 보내기 위해 잠시 대기할 수 있는 전체 메모리 바이트입니다.

- compression.type
  - 데이터를 압축해서 보낼 수 있는데, 어떤 타입으로 압출할지를 정할 수 있습니다. 옵션으로는 none, gzip, snappy, lz4 같은 다양한 포맷 중 하나를 선택할 수 있습니다.
- retries
  - 일시적인 오류로 인해 전송에 실패한 데이터를 다시 보내는 횟수입니다.

- batch.size
  - 같은 파티션으로 보내는 여러 데이터를 함께 배치로 보내려고 시도합니다. 이러한 동작은 클라이언트와 서버 양쪽에 성능적인 측면에서 도움이 됩니다. 이 설정을 통해서 배치 크기 바이트를 조정합니다. (배치 사이즈를 채우기 전에 장애가 발생하면 메시지는 날아갑니다.)
- linger.ms
  - 배치 형태의 메시지를 보내기 전에 추가적인 메시지들을 위해 기다리는 시간을 조정합니다. 카프카 프로듀서는 지정된 배치 사이즈에 도달하면 이 옵션과 관계없이 즉시 메시지를 전송하고, 배치 사이즈에 도달하지 못한 상황에서 linger.ms 제한 시간에 도달했을 때 메시지들을 전송합니다.(DEFAULT 0)

- max.request.size
  - 보낼 수 있는 메시지의 최대 바이크 사이즈입니다. (DEFAULT 1MB)

### Counsumer 주요 옵션
- bootstrap.servers
  - 정의된 포맷: kafka01:9092, kafka02:9092….
  - 전체 카프카 리스트를 적어주는 것을 권장. 하나만 사용시 장애 발생시 불능

- fetch.min.byte
  - 한번에 가져올 수 있는 최소 데이터 사이즈
  - 지정한 크기보다 작다면 데이터가 누적될 때까지 기다림

- group.id
  - 컨슈머가 속한 컨슈머 그룹을 식별하는 식별자

- enable.auto.commit
  - 백그라운드로 주기적으로 오프셋을 커밋함
  - enable.auto.commit=true 로 설정하면 5초마다 컨슈머는 poll()를 호출할 때 가장 마지막 오프셋을 커밋함(자동 커밋).
  - 5초 주기는 기본값이며, auto.commit.interval.ms 옵션을 통해 조정 가능.

- auto.offset.reset
  - 오프셋이 없는 경우(데이터가 없음)에 아래의 옵션으로 리셋함
  - earliest : 가장 초기의 오프셋 값으로 설정
  - latest : 가장 마지막의 오프셋 값으로 설정
  - none : 이전 오프셋값을 찾지 못하면 에러를 나타냄

- fetch.max.bytes
  - 한번에 가져올 수 있는 최대 데이터 사이즈

- request.timeout.ms
  - 요청에 대해 응답을 기다리는 최대 시간

- session.timeout.ms
  - 컨슈머가 살아있는 것으로 판단하는 시간(디폴트 10초)
  - 10초 안에 컨슈머가 그룹 코디네이터에게 하트비트를 보내야함
  - 10초를 넘으면 장애로 판단하고 리밸런스를 시도함
  - 세션 타임아웃이 짧다면 가비지 컬렉션이나 poll loop 완료시간이 길어지게 되어 리밸런스가 일어나기도 함.
  - 세션 타임아웃이 길다면 리밸런스보다 실제 오류 탐시 시간이 오래 걸림

- heartbeat.interval.ms
  - 그룹 코디네이터에게 얼마나 자주 KafkaConsumer poll() 메소드로 하트비트를 보낼지 조정함.
  - session.timeout.ms과 밀접하며 반드시 session.timeout.ms의 값보다 당연히 작아야 하며 일반적으로 1/3로 설정. 디폴트는 3초

- max.poll.records
  - 단일 호출 poll()에 대한 최대 레코드 수를 조정.

- max.poll.interval.ms
  - 컨슈머가 하트비트를 주기적으로 보내는데, 하트비트만 보내고 메시지를 가져가지 않은 경우, 무기한 파티션 점유를 막기 위함
  - 즉 컨슈머가 poll()을 호출하지 않으면 장애로 판단하며, 다른 컨슈머에게 메시지를 가져가도록 함.

- auto.commit.interval.ms
  - 주기적으로 오프셋을 커밋하는 시간

- fetch.max.wait.ms
  - fetch.min.bytes의 설정 데이터보다 적은 경우 요청에 응답을 기다리는 최대 시간.
  - fetch.min.bytes는 한번에 가져가는 최대 데이터 사이즈인데 무한정 데이터가 차길 기다릴 수 없으니 시간제약을 준다고 생각하자.

[참고]
- https://github.com/dpkp/kafka-python/blob/master/example.py
- https://github.com/dpkp/kafka-python
- https://kafka-python.readthedocs.io/en/master/usage.html
